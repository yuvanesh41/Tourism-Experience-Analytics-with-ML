{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import mysql.connector\n",
    "import joblib\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading datasets...\n",
      "Datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load Datasets\n",
    "print(\"Step 1: Loading datasets...\")\n",
    "city_df = pd.read_excel(\"City.xlsx\")\n",
    "continent_df = pd.read_excel(\"Continent.xlsx\")\n",
    "country_df = pd.read_excel(\"Country.xlsx\")\n",
    "item_df = pd.read_excel(\"Item.xlsx\")\n",
    "mode_df = pd.read_excel(\"Mode.xlsx\")\n",
    "region_df = pd.read_excel(\"Region.xlsx\")\n",
    "transaction_df = pd.read_excel(\"Transaction.xlsx\")\n",
    "type_df = pd.read_excel(\"Type.xlsx\")\n",
    "user_df = pd.read_excel(\"User.xlsx\")\n",
    "print(\"Datasets loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Merging datasets...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'AttractionId'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aswin\\3D Objects\\guvi_project\\project-4 tourism\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'AttractionId'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m user_df[\u001b[33m'\u001b[39m\u001b[33mUserId\u001b[39m\u001b[33m'\u001b[39m] = user_df[\u001b[33m'\u001b[39m\u001b[33mUserId\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m      5\u001b[39m transaction_df[\u001b[33m'\u001b[39m\u001b[33mAttractionId\u001b[39m\u001b[33m'\u001b[39m] = transaction_df[\u001b[33m'\u001b[39m\u001b[33mAttractionId\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m type_df[\u001b[33m'\u001b[39m\u001b[33mAttractionId\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mtype_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAttractionId\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m      7\u001b[39m user_df[\u001b[33m'\u001b[39m\u001b[33mCityId\u001b[39m\u001b[33m'\u001b[39m] = user_df[\u001b[33m'\u001b[39m\u001b[33mCityId\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m      8\u001b[39m city_df[\u001b[33m'\u001b[39m\u001b[33mCityId\u001b[39m\u001b[33m'\u001b[39m] = city_df[\u001b[33m'\u001b[39m\u001b[33mCityId\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aswin\\3D Objects\\guvi_project\\project-4 tourism\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aswin\\3D Objects\\guvi_project\\project-4 tourism\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'AttractionId'"
     ]
    }
   ],
   "source": [
    "# Step 2: Merge Datasets\n",
    "print(\"Step 2: Merging datasets...\")\n",
    "transaction_df['UserId'] = transaction_df['UserId'].astype(str)\n",
    "user_df['UserId'] = user_df['UserId'].astype(str)\n",
    "transaction_df['AttractionId'] = transaction_df['AttractionId'].astype(str)\n",
    "type_df['AttractionId'] = type_df['AttractionId'].astype(str)\n",
    "user_df['CityId'] = user_df['CityId'].astype(str)\n",
    "city_df['CityId'] = city_df['CityId'].astype(str)\n",
    "city_df['CountryId'] = city_df['CountryId'].astype(str)\n",
    "country_df['CountryId'] = country_df['CountryId'].astype(str)\n",
    "country_df['RegionId'] = country_df['RegionId'].astype(str)\n",
    "region_df['RegionId'] = region_df['RegionId'].astype(str)\n",
    "user_df['ContinentId'] = user_df['ContinentId'].astype(str)\n",
    "continent_df['ContinentId'] = continent_df['ContinentId'].astype(str)\n",
    "\n",
    "merged_df = pd.merge(transaction_df, user_df, on=\"UserId\", how=\"inner\")\n",
    "merged_df = pd.merge(merged_df, type_df, on=\"AttractionId\", how=\"inner\")\n",
    "merged_df = pd.merge(merged_df, city_df, on=\"CityId\", how=\"inner\")\n",
    "merged_df = pd.merge(merged_df, country_df, on=\"CountryId\", how=\"inner\")\n",
    "merged_df = pd.merge(merged_df, region_df, on=\"RegionId\", how=\"inner\")\n",
    "merged_df = pd.merge(merged_df, continent_df, on=\"ContenentId\", how=\"inner\")\n",
    "print(\"Datasets merged successfully.\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clean Data\n",
    "print(\"Step 3: Cleaning data...\")\n",
    "cleaned_df = merged_df.dropna()\n",
    "print(\"Data cleaned successfully.\")\n",
    "print(cleaned_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Perform EDA\n",
    "print(\"Step 4: Performing EDA...\")\n",
    "print(\"Dataset Information:\")\n",
    "print(cleaned_df.info())\n",
    "print(\"\\nDataset Description:\")\n",
    "print(cleaned_df.describe())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(cleaned_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize Data\n",
    "print(\"Step 5: Visualizing data...\")\n",
    "sns.countplot(x=\"VisitMode\", data=cleaned_df)\n",
    "plt.title(\"Visit Mode Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save to SQL\n",
    "print(\"Step 6: Saving to MySQL...\")\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"vijay45\",\n",
    "    database=\"tourism_db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS tourism_data\")\n",
    "create_table_query = '''\n",
    "CREATE TABLE tourism_data (\n",
    "    {});\n",
    "'''.format(\", \".join([f\"{col} VARCHAR(255)\" for col in cleaned_df.columns]))\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "for _, row in cleaned_df.iterrows():\n",
    "    insert_query = \"INSERT INTO tourism_data ({}) VALUES ({});\".format(\n",
    "        \", \".join(cleaned_df.columns), \", \".join([\"%s\"] * len(cleaned_df.columns)))\n",
    "    cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(\"Data saved to MySQL successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train Machine Learning Models\n",
    "print(\"Step 7: Training ML models...\")\n",
    "X = cleaned_df[[\"VisitYear\", \"VisitMonth\", \"AttractionTypeId\"]]\n",
    "y_reg = cleaned_df[\"Rating\"]\n",
    "y_clf = cleaned_df[\"VisitMode\"]\n",
    "\n",
    "X_train, X_test, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",
    "_, _, y_train_clf, y_test_clf = train_test_split(X, y_clf, test_size=0.2, random_state=42)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train_reg)\n",
    "y_pred_reg = regressor.predict(X_test)\n",
    "print(\"Regression MSE:\", mean_squared_error(y_test_reg, y_pred_reg))\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train_clf)\n",
    "y_pred_clf = classifier.predict(X_test)\n",
    "print(\"Classification Accuracy:\", accuracy_score(y_test_clf, y_pred_clf))\n",
    "\n",
    "joblib.dump(regressor, \"regressor_model.pkl\")\n",
    "joblib.dump(classifier, \"classifier_model.pkl\")\n",
    "print(\"Models trained and saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
